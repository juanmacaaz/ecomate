{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DIR_DATA = 'Final_dataset_small2'\n",
    "DIR_MODEL = 'models/xception_fine_no_freeze_flatten.h5'\n",
    "classes = os.listdir(DIR_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "from tf_keras_vis.utils.scores import CategoricalScore\n",
    "from tf_keras_vis.saliency import Saliency\n",
    "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
    "\n",
    "replace2linear = ReplaceToLinear()\n",
    "model = keras.models.load_model(DIR_MODEL)\n",
    "\n",
    "saliency = Saliency(model,\n",
    "                    model_modifier=replace2linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_pdf(x, mean=0.5, std_dev=0.15):\n",
    "    return (1.0 / (std_dev * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mean) / std_dev) ** 2)\n",
    "\n",
    "for class_index, class_ in enumerate(classes[2:]):\n",
    "    class_index += 2\n",
    "    imagenes = [d for d in os.listdir(os.path.join(DIR_DATA, class_)) if d.endswith('.jpg')]\n",
    "    for img in imagenes:\n",
    "        img_array = cv2.imread(os.path.join(DIR_DATA, class_, img)) / 255.0\n",
    "        saliency_map = saliency(CategoricalScore(class_index), img_array, smooth_samples=30, smooth_noise=0.2, normalize_map = False)[0]\n",
    "        saliency_map = (saliency_map - np.min(saliency_map)) / (np.max(saliency_map) - np.min(saliency_map))\n",
    "        if not os.path.exists(f'saliency_maps/{class_}'):\n",
    "                os.makedirs(f'saliency_maps/{class_}')\n",
    "        cv2.imwrite(f'saliency_maps/{class_}/{img[:-4]}.png', saliency_map * 255.0)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 - Marron\n",
      "3 - Medicamento\n",
      "4 - Pilas\n",
      "5 - Punto\n",
      "6 - RAEE\n",
      "7 - Resta\n",
      "8 - Ropa\n",
      "9 - Verde\n"
     ]
    }
   ],
   "source": [
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "\n",
    "sam = sam_model_registry[\"vit_h\"](checkpoint=\"sam_vit_h_4b8939.pth\")\n",
    "sam.to(device=\"cuda\")\n",
    "\n",
    "for class_index, class_ in enumerate(classes[2:]):\n",
    "    class_index += 2\n",
    "    print(f'{class_index} - {class_}')\n",
    "    imagenes = os.listdir(os.path.join(DIR_DATA, class_))\n",
    "    for j, img in enumerate(imagenes):\n",
    "        if not img.endswith('.jpg'): continue\n",
    "        try:\n",
    "            img_array = cv2.imread(os.path.join(DIR_DATA, class_, img))\n",
    "\n",
    "            mask_generator = SamAutomaticMaskGenerator(sam, stability_score_thresh = 0.7)\n",
    "            masks_results = mask_generator.generate(img_array)\n",
    "            masks = [\n",
    "                mask['segmentation']\n",
    "                for mask\n",
    "                in sorted(masks_results, key=lambda x: x['area'], reverse=True) if mask['area'] > 300\n",
    "            ]\n",
    "\n",
    "            # Get mask with the highest score compared to the heatmap\n",
    "            valid_masks = []\n",
    "\n",
    "            max_area = np.max([np.sum(mask) for mask in masks])\n",
    "\n",
    "            # Read the saliency map\n",
    "            saliency_map = cv2.imread(f'saliency_maps/{class_}/{img[:-4]}.png', cv2.IMREAD_GRAYSCALE)\n",
    "            saliency_map = saliency_map.astype(np.float32) / 255.0\n",
    "            saliency_map_mean = np.mean(saliency_map)\n",
    "            for mask in masks:\n",
    "                area = np.sum(mask)\n",
    "                mask_ = mask.astype(np.float32)\n",
    "                tmp = np.zeros((img_array.shape[0], img_array.shape[1])).astype(np.float32)\n",
    "                tmp = saliency_map\n",
    "                tmp[saliency_map < saliency_map_mean * 0.5] = -2\n",
    "                valor = np.sum((mask_ * tmp))\n",
    "                valid_masks.append((mask, valor))\n",
    "\n",
    "            valid_masks = sorted(valid_masks, key=lambda x: x[1], reverse=True)[0]\n",
    "\n",
    "            mask = valid_masks[0]\n",
    "\n",
    "            # Save mask\n",
    "            if not os.path.exists(f'masks/{class_}'):\n",
    "                os.makedirs(f'masks/{class_}')\n",
    "            cv2.imwrite(f'masks/{class_}/{img[:-4]}.png', mask * 255)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f'Error en {class_}/{img}')\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-tfg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
