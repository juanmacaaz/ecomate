{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Juanma\\anaconda3\\envs\\new-tfg\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import open_clip\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _, preprocess = open_clip.create_model_and_transforms('ViT-g-14', pretrained='laion2b_s34b_b88k')\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolderWithPaths(ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        path = self.imgs[index][0]\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = ImageFolderWithPaths(root=\"SimilarImages\", transform=transform)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "val_dataset = ImageFolderWithPaths(root=\"Final_dataset_small/Validation\", transform=transform)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "['SimilarImages\\\\Amarillo\\\\000018_00_1.jpg', 'SimilarImages\\\\Amarillo\\\\000075_00_1.jpg', 'SimilarImages\\\\Amarillo\\\\000101_00_1.jpg', 'SimilarImages\\\\Amarillo\\\\000102_00_1.jpg', 'SimilarImages\\\\Amarillo\\\\000174_00_1.jpg', 'SimilarImages\\\\Amarillo\\\\000175_00_1.jpg', 'SimilarImages\\\\Amarillo\\\\001720_00_1.jpg', 'SimilarImages\\\\Amarillo\\\\001829_00_1.jpg', 'SimilarImages\\\\Amarillo\\\\001831_00_1.jpg', 'SimilarImages\\\\Amarillo\\\\002212_00_1.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Juanma\\anaconda3\\envs\\new-tfg\\lib\\site-packages\\numpy\\lib\\npyio.py:521: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    }
   ],
   "source": [
    "def get_features(dataset):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_directories = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, paths in dataset:\n",
    "            features = model.encode_image(images.to('cuda'))\n",
    "\n",
    "            all_features.append(features)\n",
    "            all_labels.append(labels)\n",
    "            for path in paths:\n",
    "                all_directories.append(path)\n",
    "\n",
    "    return torch.cat(all_features).cpu().numpy(), torch.cat(all_labels).cpu().numpy(), all_directories\n",
    "\n",
    "train_features, train_labels, all_directories = get_features(train_dataloader)\n",
    "\n",
    "# Print first 10 features\n",
    "print(train_labels[:10])\n",
    "print(all_directories[:10])\n",
    "\n",
    "grouped = list(zip(train_features, train_labels, all_directories))\n",
    "\n",
    "# Save features\n",
    "np.save('features_clip.npy', grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "['Final_dataset_small/Validation\\\\Amarillo\\\\04DJVSJ7R468.jpg', 'Final_dataset_small/Validation\\\\Amarillo\\\\176968_00_1.jpg', 'Final_dataset_small/Validation\\\\Amarillo\\\\180544_00_1.jpg', 'Final_dataset_small/Validation\\\\Amarillo\\\\180546_00_1.jpg', 'Final_dataset_small/Validation\\\\Amarillo\\\\182322_00_1.jpg', 'Final_dataset_small/Validation\\\\Amarillo\\\\183479_00_1.jpg', 'Final_dataset_small/Validation\\\\Amarillo\\\\186443_00_1.jpg', 'Final_dataset_small/Validation\\\\Amarillo\\\\196319_00_1.jpg', 'Final_dataset_small/Validation\\\\Amarillo\\\\196826_00_1.jpg', 'Final_dataset_small/Validation\\\\Amarillo\\\\197726_00_1.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Juanma\\anaconda3\\envs\\new-tfg\\lib\\site-packages\\numpy\\lib\\npyio.py:521: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    }
   ],
   "source": [
    "def get_features(dataset):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_directories = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, paths in dataset:\n",
    "            features = model.encode_image(images.to('cuda'))\n",
    "\n",
    "            all_features.append(features)\n",
    "            all_labels.append(labels)\n",
    "            for path in paths:\n",
    "                all_directories.append(path)\n",
    "\n",
    "    return torch.cat(all_features).cpu().numpy(), torch.cat(all_labels).cpu().numpy(), all_directories\n",
    "\n",
    "train_features, train_labels, all_directories = get_features(val_dataloader)\n",
    "\n",
    "# Print first 10 features\n",
    "print(train_labels[:10])\n",
    "print(all_directories[:10])\n",
    "\n",
    "grouped = list(zip(train_features, train_labels, all_directories))\n",
    "\n",
    "# Save features\n",
    "np.save('features_clip_val.npy', grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9319727891156463\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "\n",
    "class Clasificador(nn.Module):\n",
    "    def __init__(self, num_caracteristicas=1024, num_clases=10):\n",
    "        super(Clasificador, self).__init__()\n",
    "\n",
    "        # Define las capas de la red\n",
    "        self.fc1 = nn.Linear(num_caracteristicas, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc4 = nn.Linear(256, num_clases)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Define cómo se realiza el paso hacia adelante\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=0.2)\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "\n",
    "        # No se aplica la función de activación a la última capa\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "classificador = Clasificador()\n",
    "classificador.cuda()\n",
    "\n",
    "# Load model\n",
    "classificador.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Load features\n",
    "grouped_val = np.load('features_clip_val.npy', allow_pickle=True)\n",
    "\n",
    "# Evaluate model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "features_val, labels_val, _ = zip(*grouped_val)\n",
    "\n",
    "features_val = np.array(features_val)\n",
    "\n",
    "labels_val = np.array(labels_val)\n",
    "\n",
    "preds_val = classificador(torch.from_numpy(features_val).float().cuda())\n",
    "\n",
    "print(accuracy_score(labels_val, torch.argmax(preds_val, dim=1).cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7121212121212122\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import open_clip\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = ImageFolder(root=\"test_final_images\", transform=transform)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "model, _, preprocess = open_clip.create_model_and_transforms('ViT-g-14', pretrained='laion2b_s34b_b88k')\n",
    "model.to('cuda')\n",
    "\n",
    "def get_features(dataset):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_directories = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataset:\n",
    "            features = model.encode_image(images.to('cuda'))\n",
    "\n",
    "            all_features.append(features)\n",
    "            all_labels.append(labels)\n",
    "            all_directories.append(dataset.dataset.imgs[labels.cpu().numpy()[0]][0])\n",
    "\n",
    "    return torch.cat(all_features).cpu().numpy(), torch.cat(all_labels).cpu().numpy(), all_directories\n",
    "\n",
    "train_features, train_labels, all_directories = get_features(train_dataloader)\n",
    "\n",
    "preds_val = classificador(torch.from_numpy(train_features).float().cuda())\n",
    "\n",
    "print(accuracy_score(train_labels, torch.argmax(preds_val, dim=1).cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador(\n",
      "  (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fc4): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "Accuracy: 34.69387755102041%\n",
      "Accuracy: 66.66666666666667%\n",
      "Accuracy: 71.42857142857143%\n",
      "Accuracy: 82.99319727891157%\n",
      "Accuracy: 87.07482993197279%\n",
      "Accuracy: 87.75510204081633%\n",
      "Accuracy: 88.43537414965986%\n",
      "Accuracy: 90.47619047619048%\n",
      "Accuracy: 92.51700680272108%\n",
      "Accuracy: 91.83673469387755%\n",
      "Accuracy: 90.47619047619048%\n",
      "Accuracy: 91.15646258503402%\n",
      "Accuracy: 90.47619047619048%\n",
      "Accuracy: 94.5578231292517%\n",
      "Accuracy: 93.19727891156462%\n",
      "Accuracy: 92.51700680272108%\n",
      "Accuracy: 94.5578231292517%\n",
      "Accuracy: 92.51700680272108%\n",
      "Accuracy: 92.51700680272108%\n",
      "Accuracy: 93.19727891156462%\n",
      "Accuracy: 93.19727891156462%\n",
      "Accuracy: 93.87755102040816%\n",
      "Accuracy: 92.51700680272108%\n",
      "Accuracy: 92.51700680272108%\n",
      "Accuracy: 93.87755102040816%\n",
      "Accuracy: 91.83673469387755%\n",
      "Accuracy: 92.51700680272108%\n",
      "Accuracy: 91.83673469387755%\n",
      "Accuracy: 93.87755102040816%\n",
      "Accuracy: 93.87755102040816%\n",
      "Accuracy: 91.83673469387755%\n",
      "Accuracy: 93.19727891156462%\n",
      "Accuracy: 92.51700680272108%\n",
      "Accuracy: 91.15646258503402%\n",
      "Accuracy: 91.83673469387755%\n",
      "Accuracy: 94.5578231292517%\n",
      "Accuracy: 94.5578231292517%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 94\u001b[0m\n\u001b[0;32m     91\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, torch\u001b[39m.\u001b[39mtensor(labels))\n\u001b[0;32m     93\u001b[0m \u001b[39m# Calcular los gradientes\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     96\u001b[0m \u001b[39m# Actualizar los parámetros\u001b[39;00m\n\u001b[0;32m     97\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\Juanma\\anaconda3\\envs\\new-tfg\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Juanma\\anaconda3\\envs\\new-tfg\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "\n",
    "# Load features\n",
    "grouped = np.load('features_clip.npy', allow_pickle=True)\n",
    "grouped_val = np.load('features_clip_val.npy', allow_pickle=True)\n",
    "\n",
    "class Clasificador(nn.Module):\n",
    "    def __init__(self, num_caracteristicas=1024, num_clases=2):\n",
    "        super(Clasificador, self).__init__()\n",
    "\n",
    "        # Define las capas de la red\n",
    "        self.fc1 = nn.Linear(num_caracteristicas, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc4 = nn.Linear(256, num_clases)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Define cómo se realiza el paso hacia adelante\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=0.2)\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "\n",
    "        # No se aplica la función de activación a la última capa\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Crear el modelo\n",
    "modelo = Clasificador(num_caracteristicas=1024, num_clases=10)\n",
    "print(modelo)\n",
    "\n",
    "# Definir la función de pérdida\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Definir el optimizador\n",
    "optimizer = torch.optim.Adam(modelo.parameters(), lr=0.00001)\n",
    "\n",
    "# Definir el número de épocas\n",
    "n_epochs = 3000\n",
    "\n",
    "# One hot encoding\n",
    "def one_hot_encode(arr, n_labels):\n",
    "    # Initialize the the encoded array\n",
    "    one_hot = np.zeros((np.multiply(*arr.shape), n_labels), dtype=np.float32)\n",
    "    \n",
    "    # Fill the appropriate elements with ones\n",
    "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
    "    \n",
    "    # Finally reshape it to get back to the original array\n",
    "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
    "\n",
    "    return one_hot\n",
    "\n",
    "# Batch generator\n",
    "def batch_generator(features, labels, batch_size=32, shuffle=True):\n",
    "    # Shuffle indicies\n",
    "    if shuffle:\n",
    "        index = np.arange(len(features))\n",
    "        np.random.shuffle(index)\n",
    "    \n",
    "    start = 0\n",
    "    while start < len(features):\n",
    "        end = min(start + batch_size, len(features))\n",
    "        \n",
    "        if shuffle:\n",
    "            excerpt = index[start:end]\n",
    "        else:\n",
    "            excerpt = slice(start, end)\n",
    "        \n",
    "        yield features[excerpt], labels[excerpt]\n",
    "        \n",
    "        start += batch_size\n",
    "\n",
    "\n",
    "# Iterar sobre las épocas\n",
    "index = 0\n",
    "for epoch in range(n_epochs):\n",
    "        # Iterar sobre los datos de entrenamiento\n",
    "        for features, labels in batch_generator(np.array([x[0] for x in grouped]), np.array([x[1] for x in grouped])):\n",
    "            # Reiniciar los gradientes\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Calcular la salida\n",
    "            output = modelo(torch.tensor(features))\n",
    "\n",
    "            # Calcular la pérdida\n",
    "            loss = criterion(output, torch.tensor(labels))\n",
    "\n",
    "            # Calcular los gradientes\n",
    "            loss.backward()\n",
    "\n",
    "            # Actualizar los parámetros\n",
    "            optimizer.step()\n",
    "\n",
    "            index += 1\n",
    "\n",
    "        if index % 10 != 0: continue\n",
    "\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for features, labels in batch_generator(np.array([x[0] for x in grouped_val]), np.array([x[1] for x in grouped_val]), batch_size=1):\n",
    "                # Calcular la salida\n",
    "                output = modelo(torch.tensor(features))\n",
    "\n",
    "                # Calcular la pérdida\n",
    "                loss = criterion(output, torch.tensor(labels))\n",
    "\n",
    "                # Calcular la predicción\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                predicted = predicted.cpu().numpy()\n",
    "\n",
    "                # Calcular el accuracy\n",
    "                total += labels.shape[0]\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "                # Save best model\n",
    "                if correct / total > 0.94:\n",
    "                    torch.save(modelo.state_dict(), 'best_model.pth')\n",
    "\n",
    "\n",
    "            print(f'Accuracy: {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-tfg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
